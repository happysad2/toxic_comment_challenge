{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f65a4554",
   "metadata": {},
   "source": [
    "#import libraries and data\n",
    "#original dataset taken from: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5e689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jackperry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jackperry/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/jackperry/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/jackperry/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/jackperry/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cefa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jackperry/Documents/GitHub/Toxic comment challenge/data/train-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cb8882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814fc14",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Randomly sample 10,000 rows and then do some pre-processing, we only want to build a model to determine whether text is a threat or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba60638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=10000, random_state=1)  # random_state for reproducibility\n",
    "df_selected = df_sample[['id', 'comment_text', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e355d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125418</th>\n",
       "      <td>9ed4497c64f3841d</td>\n",
       "      <td>\"\\nNo problem making 2 requests - rather, supp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126234</th>\n",
       "      <td>a32be17a2ab3770b</td>\n",
       "      <td>I await my lashings..lol.. maybe they will see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43054</th>\n",
       "      <td>72db634dfe4d23b6</td>\n",
       "      <td>You must forgive my laggard pace, Splash; been...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>73de4f62fb8f0de2</td>\n",
       "      <td>Well then, LooseTheHotButtonS, when are you go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61380</th>\n",
       "      <td>a44d0b87bceaa9fc</td>\n",
       "      <td>\"\\n\\n Thanks \\n\\nThanks for reverting my talk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116638</th>\n",
       "      <td>6f88181c6e4d01f8</td>\n",
       "      <td>Bullshit! \\n\\nThe section used to be a neat li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114966</th>\n",
       "      <td>66ca321e423ed36c</td>\n",
       "      <td>Unfamiliar word section \\n\\nBy what standard a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39841</th>\n",
       "      <td>6a5c9833ca7e8093</td>\n",
       "      <td>Extra song? (/doesn't exist) \\n\\nApparently th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138963</th>\n",
       "      <td>e7ab2600518a1333</td>\n",
       "      <td>Shutters - Use of Socket Covers \\n\\nI have rev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146754</th>\n",
       "      <td>31215789bd4b1cbe</td>\n",
       "      <td>I actually went ahead and added new figures an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>03d36498737417ed</td>\n",
       "      <td>I certainly could. But in February I decided t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74966</th>\n",
       "      <td>c88ec990a3e05cb8</td>\n",
       "      <td>\"\\nOriginal article should be like this\\n\\n \\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58111</th>\n",
       "      <td>9b9f6b3de9c46898</td>\n",
       "      <td>Wiki links\\nHi. You may not be aware, but link...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62047</th>\n",
       "      <td>a604851677f94989</td>\n",
       "      <td>are you talking to me? if so wat did i do? Use...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110600</th>\n",
       "      <td>4fa978522a15818c</td>\n",
       "      <td>\"::::::Whatever, my policy is that I think tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145729</th>\n",
       "      <td>21696029e0345ea5</td>\n",
       "      <td>\"\\n\\n Secrets from the grave \\n\\nThis is pure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128678</th>\n",
       "      <td>b02bbab7df8b6cdd</td>\n",
       "      <td>\"\\n\\n Fires and vegetation \\n\\nThe text says:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132808</th>\n",
       "      <td>c68ec2c546024987</td>\n",
       "      <td>\"\\n\\nUk55\\nI fess-up, you have caught me again...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104625</th>\n",
       "      <td>2fb2bf7c25478f16</td>\n",
       "      <td>alreajk not logging in.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>487eecc0dee4d797</td>\n",
       "      <td>Ha \\n\\nThis is true, but I bet Godwin cries hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15948</th>\n",
       "      <td>2a1168b7b6024c87</td>\n",
       "      <td>\"\\nVorangor Sub619 and I know it was just a va...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16832</th>\n",
       "      <td>2c662256d9ccb1a6</td>\n",
       "      <td>How many times is a Real Book cited in the art...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43149</th>\n",
       "      <td>7322bb6aee3d2032</td>\n",
       "      <td>\"\\n\\nHello, Sbrockway, and thank you for your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89694</th>\n",
       "      <td>eff46ec6e399443f</td>\n",
       "      <td>You \\nDonny Osmond is an arsehole! Let me post...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33868</th>\n",
       "      <td>5a50c125d6adc582</td>\n",
       "      <td>\"\\n\\n: Thanks, but I didn't create this articl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136209</th>\n",
       "      <td>d8a47a877286a0fe</td>\n",
       "      <td>Stop writing on my page. You are only making t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45415</th>\n",
       "      <td>796e68eee1e97b82</td>\n",
       "      <td>Ayup, vandalism. Fixed, thanks for noticing it!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129835</th>\n",
       "      <td>b684b389a85f6931</td>\n",
       "      <td>\"\\n\\nPS: Dear Ed, and now I see that on the ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71502</th>\n",
       "      <td>bf644d4d03faabd8</td>\n",
       "      <td>Look everyone its the queer talk page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69977</th>\n",
       "      <td>bb357bc8d71d22e3</td>\n",
       "      <td>January 2009 (UTC)\\nI have decided to retire f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50963</th>\n",
       "      <td>884dba9e5a3ac656</td>\n",
       "      <td>Vandalism \\n\\nStop vandalising pages. You are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86265</th>\n",
       "      <td>e6b800d5d3fc1c35</td>\n",
       "      <td>GO SUCK A DICK YOU BITCH, YOU CANT SOTP ME CUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74533</th>\n",
       "      <td>c76805871de1a70e</td>\n",
       "      <td>\":: When you say \"\"we\"\", I hope you're not inc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13669</th>\n",
       "      <td>2415a4a954d8e561</td>\n",
       "      <td>He's a repeat offender. When he changed Islamo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36878</th>\n",
       "      <td>627b3acf61773e70</td>\n",
       "      <td>Soxwon, I'm not attacking, but I am pointing o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023</th>\n",
       "      <td>180241551614b169</td>\n",
       "      <td>This most certainly is T.R. Knight.  He has ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20449</th>\n",
       "      <td>35f50c518514d3d8</td>\n",
       "      <td>The article Rising Collective has been speedil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147471</th>\n",
       "      <td>3cf3e6c731743f87</td>\n",
       "      <td>asserting that these differences are a consequ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132691</th>\n",
       "      <td>c5ddec7dc1e4dff5</td>\n",
       "      <td>3RR \\nYou hve reverted this statement more tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50968</th>\n",
       "      <td>8850a90a53d052c3</td>\n",
       "      <td>Please be bold and make any changes you feel a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "125418  9ed4497c64f3841d  \"\\nNo problem making 2 requests - rather, supp...   \n",
       "126234  a32be17a2ab3770b  I await my lashings..lol.. maybe they will see...   \n",
       "43054   72db634dfe4d23b6  You must forgive my laggard pace, Splash; been...   \n",
       "43409   73de4f62fb8f0de2  Well then, LooseTheHotButtonS, when are you go...   \n",
       "61380   a44d0b87bceaa9fc  \"\\n\\n Thanks \\n\\nThanks for reverting my talk ...   \n",
       "116638  6f88181c6e4d01f8  Bullshit! \\n\\nThe section used to be a neat li...   \n",
       "114966  66ca321e423ed36c  Unfamiliar word section \\n\\nBy what standard a...   \n",
       "39841   6a5c9833ca7e8093  Extra song? (/doesn't exist) \\n\\nApparently th...   \n",
       "138963  e7ab2600518a1333  Shutters - Use of Socket Covers \\n\\nI have rev...   \n",
       "146754  31215789bd4b1cbe  I actually went ahead and added new figures an...   \n",
       "1427    03d36498737417ed  I certainly could. But in February I decided t...   \n",
       "74966   c88ec990a3e05cb8  \"\\nOriginal article should be like this\\n\\n \\n...   \n",
       "58111   9b9f6b3de9c46898  Wiki links\\nHi. You may not be aware, but link...   \n",
       "62047   a604851677f94989  are you talking to me? if so wat did i do? Use...   \n",
       "110600  4fa978522a15818c  \"::::::Whatever, my policy is that I think tha...   \n",
       "145729  21696029e0345ea5  \"\\n\\n Secrets from the grave \\n\\nThis is pure ...   \n",
       "128678  b02bbab7df8b6cdd  \"\\n\\n Fires and vegetation \\n\\nThe text says:\\...   \n",
       "132808  c68ec2c546024987  \"\\n\\nUk55\\nI fess-up, you have caught me again...   \n",
       "104625  2fb2bf7c25478f16                            alreajk not logging in.   \n",
       "27395   487eecc0dee4d797  Ha \\n\\nThis is true, but I bet Godwin cries hi...   \n",
       "15948   2a1168b7b6024c87  \"\\nVorangor Sub619 and I know it was just a va...   \n",
       "16832   2c662256d9ccb1a6  How many times is a Real Book cited in the art...   \n",
       "43149   7322bb6aee3d2032  \"\\n\\nHello, Sbrockway, and thank you for your ...   \n",
       "89694   eff46ec6e399443f  You \\nDonny Osmond is an arsehole! Let me post...   \n",
       "33868   5a50c125d6adc582  \"\\n\\n: Thanks, but I didn't create this articl...   \n",
       "136209  d8a47a877286a0fe  Stop writing on my page. You are only making t...   \n",
       "45415   796e68eee1e97b82    Ayup, vandalism. Fixed, thanks for noticing it!   \n",
       "129835  b684b389a85f6931  \"\\n\\nPS: Dear Ed, and now I see that on the ar...   \n",
       "71502   bf644d4d03faabd8              Look everyone its the queer talk page   \n",
       "69977   bb357bc8d71d22e3  January 2009 (UTC)\\nI have decided to retire f...   \n",
       "50963   884dba9e5a3ac656  Vandalism \\n\\nStop vandalising pages. You are ...   \n",
       "86265   e6b800d5d3fc1c35  GO SUCK A DICK YOU BITCH, YOU CANT SOTP ME CUN...   \n",
       "74533   c76805871de1a70e  \":: When you say \"\"we\"\", I hope you're not inc...   \n",
       "13669   2415a4a954d8e561  He's a repeat offender. When he changed Islamo...   \n",
       "36878   627b3acf61773e70  Soxwon, I'm not attacking, but I am pointing o...   \n",
       "9023    180241551614b169  This most certainly is T.R. Knight.  He has ta...   \n",
       "20449   35f50c518514d3d8  The article Rising Collective has been speedil...   \n",
       "147471  3cf3e6c731743f87  asserting that these differences are a consequ...   \n",
       "132691  c5ddec7dc1e4dff5  3RR \\nYou hve reverted this statement more tha...   \n",
       "50968   8850a90a53d052c3  Please be bold and make any changes you feel a...   \n",
       "\n",
       "        threat  \n",
       "125418       0  \n",
       "126234       0  \n",
       "43054        0  \n",
       "43409        0  \n",
       "61380        0  \n",
       "116638       0  \n",
       "114966       0  \n",
       "39841        0  \n",
       "138963       0  \n",
       "146754       0  \n",
       "1427         0  \n",
       "74966        0  \n",
       "58111        0  \n",
       "62047        0  \n",
       "110600       0  \n",
       "145729       0  \n",
       "128678       0  \n",
       "132808       0  \n",
       "104625       0  \n",
       "27395        0  \n",
       "15948        0  \n",
       "16832        0  \n",
       "43149        0  \n",
       "89694        0  \n",
       "33868        0  \n",
       "136209       0  \n",
       "45415        0  \n",
       "129835       0  \n",
       "71502        0  \n",
       "69977        0  \n",
       "50963        0  \n",
       "86265        0  \n",
       "74533        0  \n",
       "13669        0  \n",
       "36878        0  \n",
       "9023         0  \n",
       "20449        0  \n",
       "147471       0  \n",
       "132691       0  \n",
       "50968        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected[20:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6de53",
   "metadata": {},
   "source": [
    "Count % of threats to determine viability of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6d46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of threats in the sample: 0.29%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of threats\n",
    "threat_count = df_selected[df_selected['threat'] == 1].shape[0]\n",
    "\n",
    "# Calculate the percentage\n",
    "total_rows = df_selected.shape[0]\n",
    "threat_percentage = (threat_count / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of threats in the sample: {threat_percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9088c",
   "metadata": {},
   "source": [
    "Insufficient %, assume > 20% threat within sample. \n",
    "Count total threats in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014817d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of threats in the total dataset: 0.2995531769557125%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of threats\n",
    "threat_count = df[df['threat'] == 1].shape[0]\n",
    "\n",
    "# Calculate the percentage\n",
    "total_rows = df.shape[0]\n",
    "threat_percentage = (threat_count / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of threats in the total dataset: {threat_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2197cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477.99999999999994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_threats_in_whole_dataset = len(df)*(threat_percentage/100)\n",
    "no_threats_in_whole_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e58a5e",
   "metadata": {},
   "source": [
    "# Break out a smaller sample size of 5,000 and include all the threats for training... assuming insufficient threats for a sample of 10,000 (only 478 positive threats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549c01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into threats and non-threats\n",
    "threats = df[df['threat'] == 1]\n",
    "non_threats = df[df['threat'] == 0]\n",
    "\n",
    "# Sample 478 threats and 4522 non-threats\n",
    "threats_sample = threats.sample(n=478, random_state=1)  # random_state for reproducibility\n",
    "non_threats_sample = non_threats.sample(n=5000-478, random_state=1)\n",
    "\n",
    "# Combine the samples\n",
    "final_sample = pd.concat([threats_sample, non_threats_sample])\n",
    "\n",
    "# Shuffle the final sample to mix threats and non-threats\n",
    "final_sample = final_sample.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddba53c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d713e9b1f6bebf36</td>\n",
       "      <td>Critical Reception \\nTop Gear is an acceptable...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e74c40f5a9e0cea1</td>\n",
       "      <td>I'm not very fond of you pegging me for editin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fdbd26ddcd879334</td>\n",
       "      <td>\"\\n The section \"\"#Dear Michael Bednarek\"\" is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417b0c66b13ded41</td>\n",
       "      <td>41, 6 July 2010 (UTC)\\n16:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b437857f7e5d02d</td>\n",
       "      <td>Well, I've been trying to do some google searc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  d713e9b1f6bebf36  Critical Reception \\nTop Gear is an acceptable...      0   \n",
       "1  e74c40f5a9e0cea1  I'm not very fond of you pegging me for editin...      1   \n",
       "2  fdbd26ddcd879334  \"\\n The section \"\"#Dear Michael Bednarek\"\" is ...      0   \n",
       "3  417b0c66b13ded41                         41, 6 July 2010 (UTC)\\n16:      0   \n",
       "4  0b437857f7e5d02d  Well, I've been trying to do some google searc...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fe590",
   "metadata": {},
   "source": [
    "OK so I need to drop the other headings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedc1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sample = final_sample[['id', 'comment_text', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5032b85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9cb2a703d610e1d5</td>\n",
       "      <td>I made no comment at all on the motivations of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>80accb846ff0f51b</td>\n",
       "      <td>Anyone editing:  Anything I do I guarantee is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a859aa2190710f4a</td>\n",
       "      <td>\"\\n\\n Page Protection \\n\\nPer a request filed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aadbf549885edec9</td>\n",
       "      <td>Material from theraputic vaccines - too techni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c06ac2ed8014bbf3</td>\n",
       "      <td>It is apparent to me that you are happy to wri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5065264585cde12b</td>\n",
       "      <td>Deletions\\nHi, I think you got confused about ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47e6223370c67857</td>\n",
       "      <td>\"\\nIf by \"\"the carrier\"\" you mean , then she i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3641689b545453ee</td>\n",
       "      <td>Please explain how my use was abusive. That us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39ddec5f32ddee74</td>\n",
       "      <td>\"\\nI was joking. As can be seen from my user p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a8491203345903b5</td>\n",
       "      <td>\"One sentence is \"\"undue weight.\"\" Please revi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>78623a20cebc2734</td>\n",
       "      <td>Truck manufacturer \\n\\nIt seems this company d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>237df5997ae8aa1f</td>\n",
       "      <td>Yes sorry for the confusion mate. As i said th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>53d890d3b08036a6</td>\n",
       "      <td>Truth counters spin. Wikipedia doesn't have a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ff278aae3290922f</td>\n",
       "      <td>Mediation\\nWill you agree to mediation?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>06611b9bcca6dfd3</td>\n",
       "      <td>Go kill yourself \\n\\nYou should be ashamed of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1e19c1dee8185f5a</td>\n",
       "      <td>And I am undoing you edit. I am trying to have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2dfd60c7a78522ac</td>\n",
       "      <td>Osli73 is an idiot \\n\\nHe wants to deface Sreb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0b4a1dd8a81b17c4</td>\n",
       "      <td>Trollop \\n\\nGo and fuck the same cross you fuc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9c6aeba226193199</td>\n",
       "      <td>Merge duplicate pages \\n\\nThere is another dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>70538b5232d18bd1</td>\n",
       "      <td>U Suck why can i not edit i am not writing any...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>65e7b70d73506e96</td>\n",
       "      <td>The problem is that most other Senators don't ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>b3e29abc98c0fc5d</td>\n",
       "      <td>\"\\n\\n Spam? Where? \\nYou keep on mentioning th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4bbc54a6627978f4</td>\n",
       "      <td>\"\\n\\nPlease discontinue your personal attacks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>c8151aed50109ca5</td>\n",
       "      <td>\"\\n\\nExcept I didn't \"\"push\"\" any \"\"fringe\"\" v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>b03378f61f41f369</td>\n",
       "      <td>I think regentspark's lead falls somewhat shor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>807168058208dc6a</td>\n",
       "      <td>I think John Milton died a few centuries ago! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4d215fc22d988331</td>\n",
       "      <td>This article has many informations not accurate!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>110b512dbc8fb5f4</td>\n",
       "      <td>as well has this users was already planning on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>917835bb6d9d789c</td>\n",
       "      <td>\"\\n\\n Invitation from WikiProject Bangladesh P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>00d0bceb5fda23f7</td>\n",
       "      <td>Oh dear, no. You've missed the point  which is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7bd6184d8fe031ef</td>\n",
       "      <td>The Divine Plan of the Ages \\n\\nPlease restore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>21cc0957fe574857</td>\n",
       "      <td>from wikiquote.  That looked cool.  So I put i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1c2678c9207832e7</td>\n",
       "      <td>As it stands now the page is unintelligible to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fd473ebb3d56c961</td>\n",
       "      <td>\"\\n, if you have any more requests, please fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f490fcfadd832954</td>\n",
       "      <td>Album Chronology \\n\\nLooking at several articl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>14e64bb79353b585</td>\n",
       "      <td>(per this discussion)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>c598e33a70c82b17</td>\n",
       "      <td>Largest Operators \\n\\nHi. you know when you de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6913c4a0c88ccfc5</td>\n",
       "      <td>\"\\n\\n Controlled-access highway \\n\\nSadly, the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>77ebc85bcb785731</td>\n",
       "      <td>huh \\n\\nhuh huh huh   \\n\\n how funny \\n\\nhow f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>b71eb63dd15dc422</td>\n",
       "      <td>To be honest, the entire section needs a rethi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>69be626d2c4f0d12</td>\n",
       "      <td>\"\\n\\nAll of you accept the truth you will need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>d6c5a2841a879071</td>\n",
       "      <td>\"\\n\\nDear Colleagues, \\nI thank the various ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>95ebdc00350058cb</td>\n",
       "      <td>dhdhhdfh \\n\\ndeleting an account isnt going to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0bf9797ee3840f55</td>\n",
       "      <td>There is not entry for video mobile, 3G phone,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9280e976fc142d02</td>\n",
       "      <td>Bonjour. I have been contracting or a while so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>99bece0b33091262</td>\n",
       "      <td>Cause they may have ancestors from English-spe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>97dd9f18ab7ee8ce</td>\n",
       "      <td>\"Featured article have much longer introductio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1e9d29141cbec887</td>\n",
       "      <td>\"\\nHmm, don't add admin, just Efe. Shawl is fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>495e8bfabb14d27a</td>\n",
       "      <td>So you're now saying that this article shouldn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>e0ecd5f71531548a</td>\n",
       "      <td>Excuse me anyone \\n\\n {{unblock| I recently re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "20  9cb2a703d610e1d5  I made no comment at all on the motivations of...   \n",
       "21  80accb846ff0f51b  Anyone editing:  Anything I do I guarantee is ...   \n",
       "22  a859aa2190710f4a  \"\\n\\n Page Protection \\n\\nPer a request filed ...   \n",
       "23  aadbf549885edec9  Material from theraputic vaccines - too techni...   \n",
       "24  c06ac2ed8014bbf3  It is apparent to me that you are happy to wri...   \n",
       "25  5065264585cde12b  Deletions\\nHi, I think you got confused about ...   \n",
       "26  47e6223370c67857  \"\\nIf by \"\"the carrier\"\" you mean , then she i...   \n",
       "27  3641689b545453ee  Please explain how my use was abusive. That us...   \n",
       "28  39ddec5f32ddee74  \"\\nI was joking. As can be seen from my user p...   \n",
       "29  a8491203345903b5  \"One sentence is \"\"undue weight.\"\" Please revi...   \n",
       "30  78623a20cebc2734  Truck manufacturer \\n\\nIt seems this company d...   \n",
       "31  237df5997ae8aa1f  Yes sorry for the confusion mate. As i said th...   \n",
       "32  53d890d3b08036a6  Truth counters spin. Wikipedia doesn't have a ...   \n",
       "33  ff278aae3290922f            Mediation\\nWill you agree to mediation?   \n",
       "34  06611b9bcca6dfd3  Go kill yourself \\n\\nYou should be ashamed of ...   \n",
       "35  1e19c1dee8185f5a  And I am undoing you edit. I am trying to have...   \n",
       "36  2dfd60c7a78522ac  Osli73 is an idiot \\n\\nHe wants to deface Sreb...   \n",
       "37  0b4a1dd8a81b17c4  Trollop \\n\\nGo and fuck the same cross you fuc...   \n",
       "38  9c6aeba226193199  Merge duplicate pages \\n\\nThere is another dis...   \n",
       "39  70538b5232d18bd1  U Suck why can i not edit i am not writing any...   \n",
       "40  65e7b70d73506e96  The problem is that most other Senators don't ...   \n",
       "41  b3e29abc98c0fc5d  \"\\n\\n Spam? Where? \\nYou keep on mentioning th...   \n",
       "42  4bbc54a6627978f4  \"\\n\\nPlease discontinue your personal attacks ...   \n",
       "43  c8151aed50109ca5  \"\\n\\nExcept I didn't \"\"push\"\" any \"\"fringe\"\" v...   \n",
       "44  b03378f61f41f369  I think regentspark's lead falls somewhat shor...   \n",
       "45  807168058208dc6a  I think John Milton died a few centuries ago! ...   \n",
       "46  4d215fc22d988331   This article has many informations not accurate!   \n",
       "47  110b512dbc8fb5f4  as well has this users was already planning on...   \n",
       "48  917835bb6d9d789c  \"\\n\\n Invitation from WikiProject Bangladesh P...   \n",
       "49  00d0bceb5fda23f7  Oh dear, no. You've missed the point  which is...   \n",
       "50  7bd6184d8fe031ef  The Divine Plan of the Ages \\n\\nPlease restore...   \n",
       "51  21cc0957fe574857  from wikiquote.  That looked cool.  So I put i...   \n",
       "52  1c2678c9207832e7  As it stands now the page is unintelligible to...   \n",
       "53  fd473ebb3d56c961  \"\\n, if you have any more requests, please fee...   \n",
       "54  f490fcfadd832954  Album Chronology \\n\\nLooking at several articl...   \n",
       "55  14e64bb79353b585                              (per this discussion)   \n",
       "56  c598e33a70c82b17  Largest Operators \\n\\nHi. you know when you de...   \n",
       "57  6913c4a0c88ccfc5  \"\\n\\n Controlled-access highway \\n\\nSadly, the...   \n",
       "58  77ebc85bcb785731  huh \\n\\nhuh huh huh   \\n\\n how funny \\n\\nhow f...   \n",
       "59  b71eb63dd15dc422  To be honest, the entire section needs a rethi...   \n",
       "60  69be626d2c4f0d12  \"\\n\\nAll of you accept the truth you will need...   \n",
       "61  d6c5a2841a879071  \"\\n\\nDear Colleagues, \\nI thank the various ad...   \n",
       "62  95ebdc00350058cb  dhdhhdfh \\n\\ndeleting an account isnt going to...   \n",
       "63  0bf9797ee3840f55  There is not entry for video mobile, 3G phone,...   \n",
       "64  9280e976fc142d02  Bonjour. I have been contracting or a while so...   \n",
       "65  99bece0b33091262  Cause they may have ancestors from English-spe...   \n",
       "66  97dd9f18ab7ee8ce  \"Featured article have much longer introductio...   \n",
       "67  1e9d29141cbec887  \"\\nHmm, don't add admin, just Efe. Shawl is fi...   \n",
       "68  495e8bfabb14d27a  So you're now saying that this article shouldn...   \n",
       "69  e0ecd5f71531548a  Excuse me anyone \\n\\n {{unblock| I recently re...   \n",
       "\n",
       "    threat  \n",
       "20       0  \n",
       "21       0  \n",
       "22       0  \n",
       "23       0  \n",
       "24       0  \n",
       "25       0  \n",
       "26       0  \n",
       "27       0  \n",
       "28       0  \n",
       "29       0  \n",
       "30       0  \n",
       "31       0  \n",
       "32       0  \n",
       "33       0  \n",
       "34       1  \n",
       "35       0  \n",
       "36       0  \n",
       "37       0  \n",
       "38       0  \n",
       "39       0  \n",
       "40       0  \n",
       "41       0  \n",
       "42       0  \n",
       "43       0  \n",
       "44       0  \n",
       "45       0  \n",
       "46       0  \n",
       "47       0  \n",
       "48       0  \n",
       "49       0  \n",
       "50       0  \n",
       "51       0  \n",
       "52       0  \n",
       "53       0  \n",
       "54       0  \n",
       "55       0  \n",
       "56       0  \n",
       "57       0  \n",
       "58       0  \n",
       "59       0  \n",
       "60       0  \n",
       "61       0  \n",
       "62       0  \n",
       "63       0  \n",
       "64       0  \n",
       "65       0  \n",
       "66       0  \n",
       "67       0  \n",
       "68       0  \n",
       "69       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have a look at 50 features..\n",
    "final_sample[20:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4af5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of threats\n",
    "threat_count = df['threat'].sum()\n",
    "threat_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe24c",
   "metadata": {},
   "source": [
    "OK now, we have a sample of 5,000 containing 478 threats and 4,522 non-threats...\n",
    "\n",
    "go straight to vectorising data, will skip the tokenisation step here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7920d",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3376182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary tools?...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6f201",
   "metadata": {},
   "source": [
    "# tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "540ea3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'This is an example of tokenization.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello! This is an example of tokenization.\"\n",
    "tokens = sent_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed54b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenizer(text):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1663ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redfine the vectorizer to also contain the tokenise step ie. integrate above function.\n",
    "vectorizer = TfidfVectorizer(tokenizer=nltk_tokenizer, stop_words='english', max_features=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242af78",
   "metadata": {},
   "source": [
    "# modified to only use training data given, the testing will be done on the training data seperately (therefore no train_test_split required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2629100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#have split the testing and training data into two parts, the testing data is 1/5 the size of the training data.\n",
    "X_train = final_sample['comment_text']\n",
    "Y_train = final_sample['threat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e770f687",
   "metadata": {},
   "source": [
    "Vectorize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "553ce844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: threat, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize text data\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "Y_train = Y_train\n",
    "\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb8ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 98, 'min_samples_leaf': 103, 'min_samples_split': 180, 'n_estimators': 148}\n"
     ]
    }
   ],
   "source": [
    "# Try Randomized Search to determine optimum hyper parameters.\n",
    "\n",
    "# Define the parameter space\n",
    "param_distributions = {\n",
    "    'n_estimators':[148],\n",
    "    'max_depth':[98],\n",
    "    'min_samples_split': randint(1, 200),  # Number of trees in random forest\n",
    "    'min_samples_leaf': randint(1, 200),      # Maximum depth of the trees\n",
    "    # other parameters and their ranges\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions, n_iter=50, cv=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11712b11",
   "metadata": {},
   "source": [
    "To manually specify class weights in a Random Forest classifier in scikit-learn, you can set the class_weight parameter to a dictionary where keys are class labels and values are the weights you wish to assign to each class. This allows you to give more importance to the minority class by assigning it a higher weight compared to the majority class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e1a19af",
   "metadata": {},
   "source": [
    "Grid search to determine hyperparameters (too computationally exhaustive, however provided insight into using class_weight = balanced.)\n",
    "\n",
    "# Manually setting class weights\n",
    "class_weights = {0: 1, 1: 2000}  # Example weights\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the grid search model\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators=100, random_state=42), param_grid, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce69dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=98, n_estimators=148,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train a Logistic Regression model, using randomised search hyperparameters.\n",
    "model = RandomForestClassifier(n_estimators=148, max_depth = 98, class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# {'max_depth': 98, 'min_samples_leaf': 14, 'min_samples_split': 95, 'n_estimators': 148}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9b26d",
   "metadata": {},
   "source": [
    "# Testing stage on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c869b78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('/Users/jackperry/Documents/GitHub/Toxic comment challenge/data/test-1.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f326d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testlabels = pd.read_csv('/Users/jackperry/Documents/GitHub/Toxic comment challenge/data/test_labels.csv')\n",
    "df_testlabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a78f6b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 id                                       comment_text\n",
       " 0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       " 1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       " 2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       " 3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       " 4  00017695ad8997eb          I don't anonymously edit articles at all.,\n",
       "                  id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       " 0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       " 1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       " 2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       " 3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       " 4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       " \n",
       "    identity_hate  \n",
       " 0             -1  \n",
       " 1             -1  \n",
       " 2             -1  \n",
       " 3             -1  \n",
       " 4             -1  )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for common column name - found 'id'\n",
    "df_test.head(), df_testlabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26ff9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of testing data before removing redundant rows:  153164\n"
     ]
    }
   ],
   "source": [
    "#join the dataframes together, pd.merge merges columns that share a common column, in this case: ID.\n",
    "df_testset = pd.merge(df_test, df_testlabels, on=\"id\")\n",
    "df_testset.head()\n",
    "\n",
    "print('length of testing data before removing redundant rows: ', len(df_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daa61b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of testing data after removing redundant rows:  63978\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where any of the columns have a value of -1\n",
    "df_testset = df_testset[df_testset != -1].dropna()\n",
    "df_testset.sample(10)\n",
    "\n",
    "print('length of testing data after removing redundant rows: ', len(df_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "810a07c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test is length: 63978\n",
      "Y_test is length: 63978\n"
     ]
    }
   ],
   "source": [
    "#break out the X and Y test data.\n",
    "Y_test = df_testset[['threat']]\n",
    "X_test = df_testset[['comment_text']]\n",
    "\n",
    "print('X_test is length:', len(X_test))\n",
    "\n",
    "print('Y_test is length:', len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55bb72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Vectorize the unseen data\n",
    "X_test_vectorized = vectorizer.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6a65a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "new_predictions = model.predict(X_test_vectorized)\n",
    "\n",
    "# Display the first ten predictions\n",
    "print(new_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51f3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put both test X and Y into the prediction algorithm.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9500d4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9926224639719904\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(Y_test, new_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab80958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     63767\n",
      "         1.0       0.26      0.65      0.37       211\n",
      "\n",
      "    accuracy                           0.99     63978\n",
      "   macro avg       0.63      0.82      0.68     63978\n",
      "weighted avg       1.00      0.99      0.99     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(Y_test, new_predictions)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444b1f5",
   "metadata": {},
   "source": [
    "Output was with the model class weights set to 2000... attempting to increase precision on class-1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.98      0.99     63767\n",
    "         1.0       0.07      0.48      0.12       211\n",
    "\n",
    "    accuracy                           0.98     63978\n",
    "   macro avg       0.53      0.73      0.55     63978\n",
    "weighted avg       1.00      0.98      0.99     63978\n",
    "\n",
    "Adjusted the model parameter to 'balanced' which means it adjusts weights inversely proportional to class frequencies..\n",
    "\n",
    "Results...\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     63767\n",
    "         1.0       0.29      0.59      0.39       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.64      0.79      0.69     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "Try: Adjust the model hyper parameters..\n",
    "\n",
    "Model = RandomForestClassifier(n_estimators=400, class_weight='balanced', random_state=42)\n",
    "\n",
    "Adjusted n_estimators to 400. parameter determines the number of trees in the forest. Generally, more trees increase the model's accuracy but also the computational cost.\n",
    "\n",
    "Results...\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      1.00     63767\n",
    "         1.0       0.28      0.60      0.38       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.64      0.80      0.69     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "\n",
    "Try n-estimators as 200...\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     63767\n",
    "         1.0       0.29      0.60      0.39       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.64      0.80      0.69     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "\n",
    "Try n-estimators as 50...\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     63767\n",
    "         1.0       0.29      0.53      0.37       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.64      0.76      0.69     63978\n",
    "weighted avg       1.00      0.99      1.00     63978\n",
    "\n",
    "Try n-estimators as 10...\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     63767\n",
    "         1.0       0.22      0.36      0.27       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.61      0.68      0.63     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "OK, so will leave as n-estimators hyper-parameter at 50 for now. Now will try setting max_depth to 10.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.75      0.86     63767\n",
    "         1.0       0.01      0.83      0.02       211\n",
    "\n",
    "    accuracy                           0.75     63978\n",
    "   macro avg       0.51      0.79      0.44     63978\n",
    "weighted avg       1.00      0.75      0.86     63978\n",
    "\n",
    "OK, leave at the default (max_depth = None which allows all the leaves to grow..)\n",
    "Now try Gridsearch which tries a range of hyper_parameters automatically.. some adjustments required..\n",
    "\n",
    "The parameter grid will search for the best max depth, min sample split and min samples leaf..\n",
    "\n",
    "Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "Create the grid search model\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators=100, random_state=42), param_grid, cv=5)\n",
    "\n",
    "Fit the model\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "Print the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "Grid search is too computationally exhaustive. Try randomized search.\n",
    "Note: grid search tests all possible combinations of hyperparameters.\n",
    "Randomized search:randomly samples a specified number of combinations from a given range for each hyperparameter\n",
    "\n",
    "Randomised search with these parameters provided the following, note the improved recall.\n",
    "\n",
    "Defined parameter space\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in random forest\n",
    "    'max_depth': randint(10, 100),      # Maximum depth of the trees\n",
    "    # other parameters and their ranges\n",
    "}\n",
    "\n",
    "the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "initialise RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      1.00     63767\n",
    "         1.0       0.23      0.63      0.34       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.61      0.81      0.67     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "Change to n_iter=40\n",
    "Best parameters: {'max_depth': 98, 'n_estimators': 148}\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      1.00     63767\n",
    "         1.0       0.26      0.65      0.37       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.63      0.82      0.68     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n",
    "Not bad, but will try randomised search for another parameter.\n",
    "\n",
    "For:\n",
    "param_distributions = {\n",
    "    'min_samples_split': randint(1, 200),  # Number of trees in random forest\n",
    "    'min_samples_leaf': randint(1, 200),      # Maximum depth of the trees\n",
    "    # other parameters and their ranges\n",
    "}\n",
    "\n",
    "and n_iter = 40\n",
    "\n",
    "Best parameters: {'min_samples_leaf': 103, 'min_samples_split': 180}\n",
    "\n",
    "Try now...\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.70      0.82     63767\n",
    "         1.0       0.01      0.82      0.02       211\n",
    "\n",
    "    accuracy                           0.70     63978\n",
    "   macro avg       0.50      0.76      0.42     63978\n",
    "weighted avg       1.00      0.70      0.82     63978\n",
    "\n",
    "Too many leafs makes the model overly simplistic...\n",
    "hyperparameter tuning can sometimes yield non-intuitive results, and it's often a matter of trial and error to find the best parameters for your specific dataset and problem.\n",
    "\n",
    "Now focus on tuning specific hyperparameters while keeping others fixed, based on prior finding.\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators':[148],\n",
    "    'max_depth':[98],\n",
    "    'min_samples_split': randint(1, 200),  # Number of trees in random forest\n",
    "    'min_samples_leaf': randint(1, 200),      # Maximum depth of the trees\n",
    "    # other parameters and their ranges\n",
    "}\n",
    "\n",
    "Best parameters: {'max_depth': 98, 'min_samples_leaf': 14, 'min_samples_split': 95, 'n_estimators': 148}\n",
    "\n",
    "At this point, randomised search doesn't seem to be helpful.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.81      0.90     63767\n",
    "         1.0       0.02      0.90      0.03       211\n",
    "\n",
    "    accuracy                           0.81     63978\n",
    "   macro avg       0.51      0.85      0.46     63978\n",
    "weighted avg       1.00      0.81      0.89     63978\n",
    "\n",
    "\n",
    "So back to default leaf settings of 1. \n",
    "\" While this might be good for capturing a lot of detail and variance from the training data, it can also lead to overfitting, where the model becomes too tailored to the training data and performs poorly on unseen data.\"\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      1.00     63767\n",
    "         1.0       0.26      0.65      0.37       211\n",
    "\n",
    "    accuracy                           0.99     63978\n",
    "   macro avg       0.63      0.82      0.68     63978\n",
    "weighted avg       1.00      0.99      0.99     63978\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70270d7",
   "metadata": {},
   "source": [
    "# test on my own text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc18bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(sample_text):\n",
    "    sample_vectorized = vectorizer.transform([sample_text])\n",
    "    sample_prediction = model.predict(sample_vectorized)# Display the prediction\n",
    "    print(\"Prediction for the given text:\")\n",
    "    print(sample_prediction[0])  # This will display the class label (0 or 1 in binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "908811ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the given text:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "make_prediction('sometimes you have to kill them')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd4a49",
   "metadata": {},
   "source": [
    "# #save model as pickl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c5f1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d005ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialise the model and save to file\n",
    "\n",
    "with open('model.plk','wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601b8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the vectoriser...\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
